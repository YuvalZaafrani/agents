{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77e84b6",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange;\">5 Workflow Design Patterns</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74103031",
   "metadata": {},
   "source": [
    "### <u>1. PROMPT CHANING </u>\n",
    "\n",
    "**הסבר:**\n",
    "- פירוק משימה לתתי משימות קבועות\n",
    "- כל תת-משימה נפתרת בנפרד, וביחד הן יוצרות את הפתרון המלא\n",
    "\n",
    "<img src=\"attachments/Screenshot 2025-09-06 162114.png\" width=\"500\">\n",
    "\n",
    "<span style=\"color:blue;\">1.</span> IN - הקלט המקורי נכנס  \n",
    "<span style=\"color:blue;\">2.</span> LLM1 - המודל הראשון מטפל בשלב הראשון של המשימה  \n",
    "<span style=\"color:blue;\">3.</span> Gate (הקופסה הכחולה) – (אופציונלי) שלב לוגיקה/קוד נוסף  \n",
    "<span style=\"color:blue;\">4.</span> LLM2 → LLM3 – מודלים נוספים לטיפול בשלבים הבאים  \n",
    "<span style=\"color:blue;\">5.</span> OUT - התוצאה הסופית יוצאת החוצה  \n",
    "<span style=\"color:orange;\">*</span> LLMS: ניתן להשתמש בכמה שרוצים \n",
    " \n",
    "<img src=\"attachments/Screenshot 2025-09-06 170016.png\" width=\"600\">\n",
    "\n",
    "המסר המרכזי:\n",
    "\n",
    "<span style=\"color:orange;\">*</span> Workflow = רצף משימות קבועות \n",
    "\n",
    "<span style=\"color:orange;\">*</span> Agent = ישות עם חופש החלטה מלא לגבי מה ואיך לבצע\n",
    "\n",
    "At Prompt Chaining, we work in a **workflow**, but sometimes we still give LLM a little freedom in intermediate decisions. \n",
    "\n",
    "### <u>2. ROUTING </u>\n",
    "\n",
    "**הסבר:**\n",
    "- במקום לפרק את המשימה לרצף שלבים קבועים\n",
    "- אנחנו נותנים ל LLMs\n",
    "- לשמש כ Router\n",
    "- כלומר, מחליט לאיזה מודל או תת־תהליך לשלוח את הקלט בהתאם לסוגו או המורכבות שלו\n",
    "\n",
    "<img src=\"attachments/Screenshot 2025-09-06 172531.png\" width=\"500\">\n",
    "\n",
    "<span style=\"color:blue;\">1.</span> IN - מגיע קלט כלשהו (שאלה, טקסט, משימה) <br>\n",
    "<span style=\"color:blue;\">2.</span> LMM Router - זהו \"שומר הסף\". הוא קורא את הקלט ומחליט: <br>\n",
    "* לאיזה LLM מתאים יותר לטפל בו <br>\n",
    "* איזה מודל הוא \"המומחה\" הנכון למשימה הזאת <br>\n",
    "\n",
    "<span style=\"color:blue;\">3.</span> LLM1 / LLM2 / LLM3 - מודלים שונים, שכל אחד מהם מותאם לתת תחום אחר <br>\n",
    "<span style=\"color:blue;\">4.</span> OUT - הפלט מהמודל הנבחר יוצא החוצה <br>\n",
    "\n",
    "### <u>3. PARALLELIZATION </u>\n",
    "\n",
    "**הסבר:**\n",
    "- פירוק משימה למספר תתי־משימות, והרצה שלהן במקביל, במקום אחת אחרי השניה\n",
    "\n",
    "<img src=\"attachments/Screenshot 2025-09-06 172609.png\" width=\"500\">\n",
    "\n",
    "<span style=\"color:blue;\">1.</span> IN - נכנס קלט ראשוני (שאלה, טקסט, משימה גדולה) <br>\n",
    "<span style=\"color:blue;\">2.</span> Coordinator - מתאם (קוד או מודל) שמפרק את המשימה הגדולה לתת־משימות עצמאיות <br>\n",
    "* למשל: חלוקה של טקסט ארוך לפסקאות שונות <br>\n",
    "\n",
    "<span style=\"color:blue;\">3.</span> LLM1 / LLM2 / LLM3 - המודלים מטפלים בתתי־משימות במקביל <br>\n",
    "* כל מודל מטפל בחלק אחר או בהיבט אחר של אותה בעיה <br>\n",
    "* למשל: LLM1 מסכם את החלק הראשון, LLM2 מסכם את החלק השני ...\n",
    "\n",
    "<span style=\"color:blue;\">4.</span> Aggregator - מאחד (קוד או מודל) את התוצאות מכל המודלים לפלט אחיד <br>\n",
    "* למשל: איחוד סיכומים מכל פסקה לטקסט שלם <br>\n",
    "\n",
    "<span style=\"color:blue;\">5.</span> OUT - התוצאה הסופית יוצאת החוצה <br>\n",
    "\n",
    "<span style=\"color:orange;\">*</span> המשימה של כל אחד לא חייבת להיות שונה (יכולה להיות), לעיתים פשוט נרצה לפרק משימה גדולה\n",
    "\n",
    "### <u>4. ORCHESTRATOR-WORKER </u>\n",
    "\n",
    "**הסבר:**\n",
    "- מודל שבו משימות מורכבות מפורקות באופן דינמי\n",
    "- לא קבוע מראש כמו ב Prompt Chaining או Parallelization\n",
    "- יש רכיב מרכזי (\"המנצח\" – Orchestrator) שמחליט בזמן אמת איך לחלק את המשימה\n",
    "- שולח אותה ל Workers (מודלים אחרים)\n",
    "- ואז יש רכיב מאחד (Synthesizer) שמחבר את הפתרונות\n",
    "\n",
    "<img src=\"attachments/Screenshot 2025-09-06 172718.png\" width=\"500\">\n",
    "\n",
    "<span style=\"color:blue;\">1.</span> IN - נכנס קלט מורכב (בעיה גדולה שצריך לפתור) <br>\n",
    "<span style=\"color:blue;\">2.</span> Orchestrator - ה\"מנצח\" שמפרק את המשימה <br>\n",
    "* מחלק את המשימה לתת־משימות דינמיות <br>\n",
    "* מחליט אילו חלקים דרושים ובאיזה סדר <br>\n",
    "* שולח את החלקים ל־ Workers (מודלים אחרים) <br>\n",
    "\n",
    "<span style=\"color:blue;\">3.</span> LLM1 / LLM2 / LLM3 - Workers <br>\n",
    "* כל Worker עובד על חלק אחר במשימה <br>\n",
    "* יכולים להיות מתמחים בתחומים שונים או להריץ חישובים שונים במקביל <br>\n",
    "\n",
    "<span style=\"color:blue;\">4.</span> Synthesizer - מאחד את הפלטים של כל ה־ Workers לפתרון אחד <br>\n",
    "<span style=\"color:blue;\">5.</span> OUT - הפתרון הסופי יוצא החוצה <br>\n",
    "\n",
    "**ההבדל מול Parallelization:**\n",
    "* Parallelization: המשימה מפורקת מראש לחלקים קבועים, והם רצים במקביל.\n",
    "* Orchestrator–Worker: הפירוק דינמי, מתבצע בזמן אמת לפי הצורך והמורכבות.\n",
    "\n",
    "### <u>5. EVALUATOR-OPTIMIZER </u>\n",
    "\n",
    "**הסבר:**\n",
    "- מודל אחד מייצר תשובה (Generator)\n",
    "- מודל אחר בודק אותה (Evaluator)\n",
    "- אם היא לא מספיק טובה – מחזירים אותה עם פידבק לשיפור, עד שהיא מתקבלת\n",
    "\n",
    "\n",
    "<img src=\"attachments/Screenshot 2025-09-06 172433.png\" width=\"500\">\n",
    "\n",
    "<span style=\"color:blue;\">1.</span> IN - נכנס קלט (שאלה או משימה) <br>\n",
    "<span style=\"color:blue;\">2.</span> LLM Generator - מודל שמייצר פתרון ראשוני <br>\n",
    "<span style=\"color:blue;\">3.</span> LLM Evaluator - מודל שבודק את הפתרון <br>\n",
    "* אם הוא טוב -\n",
    "\n",
    " הפתרון מתקבל ועובר ל OUT <br>\n",
    "* אם הוא לא טוב -\n",
    "\n",
    " נדחה עם פידבק וחוזר ל Generator לשיפור <br>\n",
    "\n",
    "<span style=\"color:blue;\">4.</span> OUT - הפתרון שעבר ולידציה יוצא החוצה <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac0df7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af013c57",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange;\">Agents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d6cbe",
   "metadata": {},
   "source": [
    "* No fixed path\n",
    "אין מסלול קבוע – הסוכן יכול לבחור פעולות בהתאם למצב\n",
    "* Feedback Loops\n",
    "הסוכן פועל, בודק את התוצאה ומחליט איך להמשיך\n",
    "* Open-ended\n",
    "לא יודעים מראש כמה צעדים יידרשו או לאן זה יוביל\n",
    "\n",
    "<img src=\"attachments/Screenshot 2025-09-06 202057.png\" width=\"500\">\n",
    "\n",
    "<span style=\"color:blue;\">1.</span> HUMAN – המשתמש נותן הוראה ראשונית <br>\n",
    "<span style=\"color:blue;\">2.</span> LLM Call – המודל מחליט איזו פעולה לבצע <br>\n",
    "<span style=\"color:blue;\">3.</span> ENVIRONMENT – העולם/סביבה מגיבה לפעולה <br>\n",
    "<span style=\"color:blue;\">4.</span> STOP – הסוכן יכול להחליט מתי לסיים את התהליך <br>\n",
    "\n",
    "<h3 style=\"color:blue;\">Risks of Agent Frameworks:</h3>\n",
    "\n",
    "1. מסלול לא צפוי (Unpredictable path):\n",
    "* אין לך מושג מראש באיזה סדר המשימות יבוצעו\n",
    "* ייתכן שחלק מהמשימות לא יבוצעו כלל\n",
    "* גם התוצאה עצמה לא ידועה מראש — אין שום הבטחה שהתוצר יהיה איכותי\n",
    "2. אי־ודאות מובנית:\n",
    "* כשאתה נותן ל־ LLMs\n",
    "* אוטונומיה להחליט איך לפתור בעיות, אתה מאפשר להם להתמודד עם בעיות גדולות ומורכבות יותר\n",
    "* מצד שני, זה מביא איתו חוסר ודאות גדול — כי הם בוחרים בעצמם את הדרך\n",
    "3. עלויות לא צפויות (Unpredictable costs):\n",
    "* לא ברור כמה זמן זה ייקח\n",
    "* ולכן גם לא ברור כמה זה יעלה בהרצת ה־ APIs\n",
    "* יכול להיווצר חשבון גדול ולא צפוי\n",
    "\n",
    "<u>איך מתמודדים עם החסרונות? (Mitigations)</u>\n",
    "1. Monitoring (ניטור):\n",
    "* היכולת לראות מה קורה בזמן אמת בתוך מערכת Agentic\n",
    "* לראות איך המודלים מתקשרים אחד עם השני\n",
    "* כלים שדיבר עליהם:\n",
    "OpenAI SDK – מאפשר לראות Trace (מעקב אחר האינטראקציות)\n",
    "LangSmith – כלי ייעודי שנותן שקיפות וויזואליזציה של תהליכי Agent\n",
    "\n",
    "דוגמא - כל שלב מקבל \"מדבקה\" שמדווחת כמה זמן לקח ומה החזיר\n",
    "\n",
    "import time <br>\n",
    "def monitored_step(step_name, func, *args): <br>\n",
    "    start = time.time() <br>\n",
    "    result = func(*args) <br>\n",
    "    end = time.time() <br>\n",
    "    print(f\"{step_name} took {end-start:.2f} sec, output: {result[:50]}\") <br>\n",
    "    return result <br>\n",
    "\n",
    "2. Guardrails (מעקות הגנה):\n",
    "* אלו מנגנוני הגנה שכותבים בתוכנה, כדי לוודא שהמודלים פועלים בתוך הגבולות שהוגדרו\n",
    "* guardrails מבטיחים שהמודלים יתנהגו : \n",
    "* בצורה בטוחה\n",
    "* באופן עקבי\n",
    "* בתוך המסגרת שהגדרנו להם\n",
    "* OpenAI Agents SDK כולל הרבה פונקציות שמיועדות בדיוק לזה\n",
    "\n",
    "דוגמא - להכריח את המודל תמיד להחזיר תשובה בפורמט JSON\n",
    "\n",
    "{ <br>\n",
    "  \"answer\": \"...\", <br>\n",
    "  \"confidence\": 0-1 <br>\n",
    "} <br>\n",
    "\n",
    "def guardrail_check(output): <br>\n",
    "    if not output.startswith(\"{\") or not output.endswith(\"}\"): <br>\n",
    "        raise ValueError(\"Output must be JSON\") <br>\n",
    "    return output <br>\n",
    "\n",
    "כאן guardrail מוודא שכל תשובה תהיה JSON תקין\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c563d27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126515f1",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange;\">Agentic AI Frameworks :</h2>\n",
    "\n",
    "**Framework = קיצור דרך + סדר עבודה מוגדר :**\n",
    "* זה בעצם סט כלים, ספריות, וקוד עוטף שמקל על פיתוח\n",
    "* במקום לכתוב הכול מאפס – המסגרת מספקת תבניות מוכנות, חיבורים, ו־ best practices\n",
    "* שמאפשרים לך להתמקד בלוגיקה העסקית ולא בפרטים הטכניים\n",
    "\n",
    "המטרה שלהן היא לספק <br>\n",
    "קוד דבק (glue code) או קוד הפשטה (abstraction) <br>\n",
    "שמסתיר את הפרטים הטכניים של עבודה עם LLMs, <br>\n",
    "ונותן מסגרת אלגנטית לבניית פתרונות agentic <br>\n",
    "תוך מיקוד בבעיה העסקית שמנסים לפתור <br>\n",
    "\n",
    "\n",
    "| שם המסגרת              | רמת מורכבות       | יתרונות                                                                 | חסרונות                                                                                     | שימושים אופייניים                                                                 |\n",
    "|-------------------------|-------------------|------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------|\n",
    "| **בלי מסגרת (Direct API)** | הכי פשוטה          | שליטה מלאה בפרומפטים, שקיפות מלאה \"מתחת למכסה המנוע\", גמישות מוחלטת     | דורש יותר קוד ידני, אין קוד דבק שמפשט, פחות נוח בפרויקטים גדולים                           | ניסויים ראשונים, פרויקטים קלים, למידה והבנה עמוקה של אינטראקציה עם LLMs          |\n",
    "| **MCP (Model Context Protocol)** | פשוטה (פרוטוקול, לא מסגרת) | סטנדרט פתוח, מאפשר חיבור מודלים לכלים ולנתונים בלי קוד דבק, גמיש         | חדש יחסית, דורש קונפורמיות לפרוטוקול, קהילה קטנה יותר                                      | אינטגרציה של מקורות מידע וכלים עם מודלים בקוד פתוח, מערכות מודולריות             |\n",
    "| **OpenAI Agents SDK**   | בינונית–נמוכה     | קל, נקי, גמיש, פשטות מרבית, אינטגרציה טובה עם OpenAI                   | עדיין צעיר, API משתנה לעיתים קרובות, פחות יכולות מתקדמות                                   | בניית Agents מהירה, POCs, פרויקטים עם OpenAI                                     |\n",
    "| **CrewAI**              | בינונית           | ותיק יותר, קל לשימוש, תומך ב־low-code (YAML), גמיש                     | מעט כבד יותר מה־SDK, פחות \"חופש קוד מלא\"                                                   | בניית צוותי Agents עם קונפיגורציה, יישומים עסקיים חצי-טכניים                    |\n",
    "| **LangGraph**           | מורכבת            | מאוד חזקה, מאפשרת בניית גרף חישובי של Agents וכלים, יכולות מתקדמות מאוד | עקומת למידה גבוהה, דורש להיכנס לאקוסיסטם, \"בולע\" את הפרויקט                              | מערכות מורכבות, אורקסטרציה מרובת־שלבים, פרויקטים מחקריים ותעשייתיים גדולים      |\n",
    "| **Autogen (Microsoft)** | מורכבת            | מספקת מספר יכולות מתקדמות, גמישות בעבודה עם Agents, שיתופי פעולה        | כבד יחסית, דורש כניסה לאקוסיסטם, עקומת למידה, פחות אינטואיטיבי                           | פרויקטים גדולים בארגונים, פתרונות Enterprise, אינטגרציה עם מוצרי מיקרוסופט       |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63b8a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0d41603",
   "metadata": {},
   "source": [
    "# Resources & Tools\n",
    "\n",
    "## 🧩 Resources (משאבים)\n",
    "- **הגדרה:** מתן קונטקסט נוסף ל־LLM כדי לשפר את המומחיות שלו.\n",
    "- **איך עושים את זה:** מוסיפים לפרומפט מידע רלוונטי (למשל: מחירי כרטיסי טיסה).\n",
    "- **יתרון:** המודל יכול להיעזר במידע בזמן התשובה.\n",
    "- **מתקדם:** לא חייבים לשים *את כל המידע*, אלא רק את הרלוונטי → תחום שנקרא **RAG (Retrieval Augmented Generation)**.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Tools (כלים)\n",
    "- **הגדרה:** מתן יכולת ל־LLM להפעיל פעולה חיצונית (אוטונומיה).\n",
    "- **דוגמאות לכלים:**\n",
    "  - ביצוע שאילתת SQL על בסיס נתונים.\n",
    "  - שימוש במחשבון.\n",
    "  - שליחת הודעה ל־LLM אחר.\n",
    "  - הפעלת שירות חיצוני (כמו \"הדלקת אורות\").\n",
    "- **איך זה עובד בפועל:**\n",
    "\n",
    "<img src=\"attachments/Screenshot 2025-09-07 195755.png\" width=\"300\">\n",
    "\n",
    "  1. בפרומפט אומרים ל־LLM אילו כלים קיימים.\n",
    "  2. ה־LLM מחזיר בקשה ב־**JSON** (למשל: `{\"action\": \"turn_on_lights\"}`).\n",
    "  3. הקוד שלנו מריץ **if statement**:\n",
    "     - אם LLM ביקש `turn_on_lights` → מבצעים פעולה.\n",
    "     - מחזירים חזרה את התוצאה ל־LLM.\n",
    "- **המציאות:** זה לא קסם → הכל JSON ו־if statements, אבל זה יוצר מראית עין של אוטונומיה.\n",
    "- **דוגמה:**\n",
    "  - שאלה: \"כמה עולה כרטיס לפריז?\"\n",
    "  - תשובת LLM: `\"use tool to fetch_ticket_price for Paris\"`\n",
    "  - הקוד מריץ את הפונקציה, מחזיר מחיר, ושולח שוב ל־LLM.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔑 נקודות חשובות\n",
    "- **Resources** = הרחבת קונטקסט (מידע נוסף בפרומפט).\n",
    "- **Tools** = יכולת להריץ פעולה אמיתית מחוץ ל־LLM.\n",
    "- **RAG** = טכניקה חכמה לשלוף רק מידע רלוונטי.\n",
    "- **האמת על Tools:** בסופו של דבר JSON + תנאי `if`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901f330",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
