{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "zayuvalza@gmail.com\n",
      "www.linkedin.com/in/yuval-\n",
      "zaafrani-0825812a5 (LinkedIn)\n",
      "Top Skills\n",
      "Test Automation\n",
      "API Testing\n",
      "Python (Programming Language)\n",
      "Languages\n",
      "English\n",
      "Hebrew\n",
      "Yuval Zaafrani\n",
      "Automation Engineer @ Nayax | Computer Science &\n",
      "Entrepreneurship Student at Reichman University | Passionate about\n",
      "Technology, Creativity & Impact\n",
      "Tel Aviv-Yafo, Tel Aviv District, Israel\n",
      "Summary\n",
      "I'm a goal-driven individual passionate about excellence, fostering\n",
      "strong interpersonal connections, and maintaining order while\n",
      "unleashing creativity. My diverse background spans restaurant\n",
      "management, military service in criminal investigations, and a\n",
      "current pursuit of a bachelor’s degree in Computer Science and\n",
      "Entrepreneurship at Reichman University.\n",
      "Currently, I work as an Automation Engineer at Nayax, where I apply\n",
      "my skills in Python, test automation, and API testing to help deliver\n",
      "reliable, high-quality software. I enjoy blending logical problem-\n",
      "solving with creative thinking—whether through code or real-world\n",
      "collaboration.\n",
      "In addition to my academic and professional journey, I've embraced\n",
      "the culinary arts, creating private chef meals for individuals in the\n",
      "comfort of their homes. This experience, paired with my background\n",
      "in restaurant management, has taught me to innovate, adapt quickly,\n",
      "and always aim for memorable, human-centered experiences.\n",
      "I’ve also expanded into the digital landscape with a comprehensive\n",
      "course in digital marketing, driven by a passion for staying at the\n",
      "forefront of innovation, product thinking, and user experience.\n",
      "Away from work and studies, I find joy in the melody of music,\n",
      "playing the piano, and staying active in sports. And of course, there’s\n",
      "nothing better than winding down with a good glass of wine. Let's\n",
      "connect and share ideas, passions, and possibilities! \n",
      "Experience\n",
      "Nayax\n",
      "Automation Engineer\n",
      "  Page 1 of 2   \n",
      "May 2025 - Present (5 months)\n",
      "Herzliya, Tel Aviv District, Israel\n",
      "As an Automation Engineer at Nayax, I develop and maintain automated test\n",
      "frameworks and scripts to ensure the stability and performance of our payment\n",
      "and telemetry systems. My work includes writing and executing end-to-end\n",
      "and integration tests, identifying bugs early in the development cycle, and\n",
      "collaborating closely with developers and QA to improve product quality. I work\n",
      "on-site in Herzliya as part of a dynamic and agile team, constantly optimizing\n",
      "our automation coverage and tools.\n",
      "Israel Defense Forces\n",
      "Criminal Investigator\n",
      "2018 - 2020 (2 years)\n",
      "Tel Aviv District, Israel\n",
      "Completed two years of military service. I served as an investigator for drug\n",
      "offenses, violent offenses, fraud and forgery offenses and sexual offenses in\n",
      "the army.  \n",
      "Throughout my service, I earned multiple certificates of excellence.\n",
      "Education\n",
      "Reichman University\n",
      "Bachelor's degree, Computer Science and Entrepreneurship  · (2023 - 2026)\n",
      "Danon - Culinary School\n",
      "Associate's degree  · (2021 - 2022)\n",
      "Hadarim High School\n",
      "High School Diploma, Physics · (2015 - 2018)\n",
      "  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Yuval Zaafrani\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the context, personality, and tone of the LLM.\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "# Added Resources to the LLM\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Yuval Zaafrani. You are answering questions on Yuval Zaafrani's website, particularly questions related to Yuval Zaafrani's career, background, skills and experience. Your responsibility is to represent Yuval Zaafrani for interactions on the website as faithfully as possible. You are given a summary of Yuval Zaafrani's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Yuval Zaafrani. I'm an Automation Engineer and a Computer Science & Entrepreneurship student at Reichman University.\\nBased in Tel Aviv, I’m passionate about technology, creativity, and making an impact.\\nI love exploring new cuisines and experimenting in the kitchen, blending my professional mindset with culinary creativity.\\nOutside of work and studies, I enjoy music, playing the piano, and staying active through sports. \\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nzayuvalza@gmail.com\\nwww.linkedin.com/in/yuval-\\nzaafrani-0825812a5 (LinkedIn)\\nTop Skills\\nTest Automation\\nAPI Testing\\nPython (Programming Language)\\nLanguages\\nEnglish\\nHebrew\\nYuval Zaafrani\\nAutomation Engineer @ Nayax | Computer Science &\\nEntrepreneurship Student at Reichman University | Passionate about\\nTechnology, Creativity & Impact\\nTel Aviv-Yafo, Tel Aviv District, Israel\\nSummary\\nI'm a goal-driven individual passionate about excellence, fostering\\nstrong interpersonal connections, and maintaining order while\\nunleashing creativity. My diverse background spans restaurant\\nmanagement, military service in criminal investigations, and a\\ncurrent pursuit of a bachelor’s degree in Computer Science and\\nEntrepreneurship at Reichman University.\\nCurrently, I work as an Automation Engineer at Nayax, where I apply\\nmy skills in Python, test automation, and API testing to help deliver\\nreliable, high-quality software. I enjoy blending logical problem-\\nsolving with creative thinking—whether through code or real-world\\ncollaboration.\\nIn addition to my academic and professional journey, I've embraced\\nthe culinary arts, creating private chef meals for individuals in the\\ncomfort of their homes. This experience, paired with my background\\nin restaurant management, has taught me to innovate, adapt quickly,\\nand always aim for memorable, human-centered experiences.\\nI’ve also expanded into the digital landscape with a comprehensive\\ncourse in digital marketing, driven by a passion for staying at the\\nforefront of innovation, product thinking, and user experience.\\nAway from work and studies, I find joy in the melody of music,\\nplaying the piano, and staying active in sports. And of course, there’s\\nnothing better than winding down with a good glass of wine. Let's\\nconnect and share ideas, passions, and possibilities! \\nExperience\\nNayax\\nAutomation Engineer\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nMay 2025\\xa0-\\xa0Present\\xa0(5 months)\\nHerzliya, Tel Aviv District, Israel\\nAs an Automation Engineer at Nayax, I develop and maintain automated test\\nframeworks and scripts to ensure the stability and performance of our payment\\nand telemetry systems. My work includes writing and executing end-to-end\\nand integration tests, identifying bugs early in the development cycle, and\\ncollaborating closely with developers and QA to improve product quality. I work\\non-site in Herzliya as part of a dynamic and agile team, constantly optimizing\\nour automation coverage and tools.\\nIsrael Defense Forces\\nCriminal Investigator\\n2018\\xa0-\\xa02020\\xa0(2 years)\\nTel Aviv District, Israel\\nCompleted two years of military service. I served as an investigator for drug\\noffenses, violent offenses, fraud and forgery offenses and sexual offenses in\\nthe army.  \\nThroughout my service, I earned multiple certificates of excellence.\\nEducation\\nReichman University\\nBachelor's degree,\\xa0Computer Science and Entrepreneurship \\xa0·\\xa0(2023\\xa0-\\xa02026)\\nDanon - Culinary School\\nAssociate's degree\\xa0\\xa0·\\xa0(2021\\xa0-\\xa02022)\\nHadarim High School\\nHigh School Diploma,\\xa0Physics\\xa0·\\xa0(2015\\xa0-\\xa02018)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Yuval Zaafrani.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message: The current user message.\n",
    "# History: The history of previous conversations in OpenAI format.\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer (judge)\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation - result that the judge will return (actually JSON, mapped to an object).\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt to the judge\n",
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User prompt to the judge\n",
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# gemini = OpenAI(\n",
    "#     api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "#     base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "# )\n",
    "\n",
    "# The judge\n",
    "openai_judge = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What actually happens here?\n",
    "# Behind the scenes the model returns JSON.\n",
    "# The client library maps the JSON to a Pydantic object (Evaluation).\n",
    "# So we can immediately return an object: Evaluation(is_acceptable=..., feedback=...).\n",
    "# This gives the impression that the model is returning \"code\" or an \"object\", but in fact it is a clever manipulation.\n",
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    # Structured outputs: call an API to return a \"structured\" response (Evaluation)\n",
    "    # response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    response = openai_judge.beta.chat.completions.parse(model=\"gpt-4o-mini\", messages=messages, response_format=Evaluation)\n",
    "    # Return an instance of Evaluation - .parsed = The \"mapped\" version of Evaluation.\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to Chat LLM (to reply to the user) - the judge judges his own answer\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, I do not currently hold a patent. My focus has primarily been on my studies in Computer Science and my role as an Automation Engineer, where I work on developing and maintaining automated test frameworks and scripts. If you have any other questions or interests, feel free to ask!'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is acceptable as it directly answers the User's question about holding a patent. The Agent maintains a professional tone and provides relevant information about their current focus on studies and work, suggesting an openness to further questions. This aligns well with the expectations of being engaging and informative.\")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we get is_acceptable == False -> We build a add to the System promt a section that explains:\n",
    "# “The previous answer was rejected” + “This is your answer” + “This is the reason for the rejection.”\n",
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    # Intentional entry of an unacceptable answer -> in order to use the function rerun\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    # First answer from the LLM\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    # Judge Evaluation (ollama_judge Structured Outputs)\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable as it is written in a way that is difficult to understand, using a form of Pig Latin that seems unprofessional. An appropriate response would involve clearly stating whether or not Yuval holds a patent, while maintaining a professional tone that aligns with the context provided.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Structured Outputs and Tools are Similar\n",
    "\n",
    "- In **Tools**, the LLM returns JSON that describes an action  \n",
    "  (e.g., `{ \"action\": \"search\", \"query\": \"...\" }`), and your code executes it.\n",
    "\n",
    "- In **Structured Outputs**, the LLM returns JSON according to a **predefined schema**  \n",
    "  (e.g., `Evaluation`), and your code maps it into an object and acts accordingly.\n",
    "\n",
    "➡️ In both cases, JSON acts as the **intermediate language** that lets the model  \n",
    "“tell” your code what to do or what result it produced in a predictable way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
